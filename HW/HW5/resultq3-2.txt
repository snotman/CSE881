>> lambda = logspace(-3,3,11); % create a set of lambda values
>> sigma = logspace(-3,3,11); % create a set of kernel scale values
>> cvloss = zeros(11,11); % stores the CV error for each (lambda,sigma) pair
>> CPER1=0

CPER1 =

     0

>> Lam1=0

Lam1 =

     0

>> for k=1:10
    testID = (indices == k); %id of test data in kth round
    trainID = ~testID; %id of train data in kth round
    Xtrain = X(trainID,:);
    Ytrain = Y(trainID);
    Xtest = X(testID,:);
    Ytest = Y(testID);
    for i=1:11
        for j=1:11
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            %it takes too much time!!
            %ask Dr. Tan
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        SVMmodel = fitcsvm(Xtrain, Ytrain, 'KernelFunction','RBF','KernelScale',sigma(j),'BoxConstraint',lambda(i),'Kfold', 5);
        cvloss(i,j)=kfoldLoss(SVMmodel);
        end;
    end;
    SVMmodel = fitcsvm(Xtrain, Ytrain, 'KernelFunction','RBF','KernelScale',0.1,'BoxConstraint',0.1,'Kfold', 5);
    cvloss(i,j)=kfoldLoss(SVMmodel);
    mincvloss=min(cvloss);
    [i1,j1]=find(cvloss==mincvloss(1));
    i1=i1(1);
    j1=j1(1);
    bestLambda=lambda(i1);
    bestSigma=sigma(j1);
    SVMmodel = fitcsvm(Xtrain, Ytrain,'KernelFunction','RBF','KernelScale',bestSigma,'BoxConstraint',bestLambda);
    pred = predict(SVMmodel, Xtest);
    cp = classperf(Ytest);
    classperf(cp,pred);
    cp.DiagnosticTable % to show the confusion matrix
    cp.ErrorRate % to show the classification error
    CPER1(k)=cp.ErrorRate;
    Lam1(k)=bestLambda;
end;

Message from syslogd@arctic at Oct 10 11:27:36 ...
 kernel:[2262038.444006] Uhhuh. NMI received for unknown reason 20 on CPU 5.

Message from syslogd@arctic at Oct 10 11:27:36 ...
 kernel:[2262038.444006] Do you have a strange power saving mode enabled?

Message from syslogd@arctic at Oct 10 11:27:36 ...
 kernel:[2262038.444006] Dazed and confused, but trying to continue

ans =

   299   131
     2    28


ans =

    0.2891

Operation terminated by user during classreg.learning.impl.SVMImpl.make (line 506)


In ClassificationSVM (line 328)
            this.Impl = classreg.learning.impl.SVMImpl.make(...

In classreg.learning.FitTemplate/fit (line 258)
            [varargout{1:nargout}] = this.MakeFitObject(X,Y,W,this.ModelParams,fitArgs{:});

In classreg.learning.ensemble.Ensemble/fitWeakLearners (line 182)
                        trainableH = fit(learners{l},X,Y,'weights',W,optArgs{:});

In classreg.learning.classif.ClassificationEnsemble/fitEnsemble (line 341)
                fitWeakLearners(this,nlearn,this.ModelParams.NPrint);

In classreg.learning.classif.ClassificationEnsemble (line 75)
            this = fitEnsemble(this,nlearn);

In classreg.learning.partition.ClassificationPartitionedModel (line 159)
            this.Ensemble = classreg.learning.classif.ClassificationEnsemble(...

In classreg.learning.FitTemplate/fit (line 258)
            [varargout{1:nargout}] = this.MakeFitObject(X,Y,W,this.ModelParams,fitArgs{:});

In ClassificationSVM.fit (line 239)
            this = fit(temp,X,Y);

In fitcsvm (line 278)
obj = ClassificationSVM.fit(X,Y,varargin{:});
 
>> cvloss

cvloss =

    0.3951    0.3951    0.3951    0.3951    0.3951    0.3951    0.3951    0.3951    0.3951    0.3951    0.3951
    0.3951    0.3951    0.3951    0.3951    0.3994    0.3994    0.3994    0.3994    0.3982    0.3246    0.3946
    0.3994    0.3994    0.3994    0.3994    0.3994    0.3994    0.3994    0.3992    0.3055    0.3060    0.3412
    0.3994    0.3994    0.3994    0.3994    0.3994    0.3994    0.3994    0.2799    0.2912    0.3031    0.3262
    0.3977    0.3958    0.3946    0.3919    0.3902    0.3876    0.3381    0.2458    0.2630    0.2912    0.3086
    0.3535    0.3441    0.3306    0.3130    0.3089    0.2842    0.2176    0.1702    0.2258    0.2755    0.3050
    0.3547    0.3432    0.3275    0.3151    0.3084    0.2845    0.2057    0.1447    0.1524    0.2507    0.2702
    0.3562    0.3429    0.3308    0.3127    0.3023    0.2799    0.2070    0.1280    0.1183    0.1855    0.2661
    0.3557    0.3441    0.3301    0.3195    0.3077    0.2801    0.2111    0.1268    0.0968    0.1263    0.2396
    0.3564    0.3448    0.3236    0.3142    0.3023    0.2823    0.2200    0.1309    0.0910    0.0944    0.1553
    0.3560    0.3458    0.3272    0.3149    0.3043    0.2830    0.2147    0.1314    0.0833    0.0778    0.3994

>> 
